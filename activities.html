<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Activities & Events - BAISH - Buenos Aires AI Safety Hub</title>
    <meta name="description" content="Explore our activities and events at the BAISH - Buenos Aires AI Safety Hub">
    <!-- Open Graph tags for social sharing -->
    <meta property="og:title" content="Activities & Events - BAISH - Buenos Aires AI Safety Hub">
    <meta property="og:description" content="Explore our activities and events at the BAISH - Buenos Aires AI Safety Hub">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://lucadeleo.github.io/aisafetysite/activities.html">
    <!-- Favicon -->
    <link rel="icon" href="img/favicon.ico">
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Source+Serif+Pro:wght@400;600&display=swap" rel="stylesheet">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header class="site-header">
        <div class="container">
            <div class="logo">
                <a href="index.html">BAISH - Buenos Aires AI Safety Hub</a>
            </div>
            <nav class="main-nav">
                <ul>
                    <li><a href="about.html">About</a></li>
                    <li><a href="activities.html" class="active">Activities</a></li>
                    <li><a href="resources.html">Resources</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </nav>
            <a href="contact.html" class="btn btn-primary">Join Us</a>
        </div>
    </header>

    <section class="page-header">
        <div class="container">
            <div class="breadcrumb">
                <a href="index.html">Home</a> / <span>Activities</span>
            </div>
            <h1>Our Activities</h1>
            <p class="subtitle">Join our community and participate in AI safety research and learning</p>
        </div>
    </section>

    <section id="agi-fundamentals" class="activity-detail">
        <div class="container">
            <div class="activity-header">
                <div class="activity-icon">üìö</div>
                <h2>AGI Safety Fundamentals Cohort</h2>
                <span class="status active">Currently Active</span>
            </div>
            <div class="activity-content">
                <div class="activity-description">
                    <p>The AGI Safety Fundamentals cohort is an 8-week guided course covering the essential concepts in AI alignment and safety. Participants read selected materials and meet weekly to discuss the readings with a facilitator.</p>
                    <p>This program is based on the AGI Safety Fundamentals curriculum by BlueDot and provides a structured introduction to the field of AI safety.</p>

                    <h3>What to Expect</h3>
                    <ul>
                        <li>Weekly 2-hour discussion sessions</li>
                        <li>1-3 hours of reading per week</li>
                        <li>Small groups of 6-12 participants</li>
                        <li>Experienced facilitators to guide discussions</li>
                        <li>Certificate of completion</li>
                    </ul>
                </div>
                <div class="activity-sidebar">
                    <div class="activity-details-card">
                        <h3>Program Details</h3>
                        <ul class="details-list">
                            <li><strong>Duration:</strong> 10-12 weeks</li>
                            <li><strong>Fellowship Period:</strong> August - December 2025</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="weekly-discussion" class="activity-detail">
        <div class="container">
            <div class="activity-header">
                <div class="activity-icon">üí¨</div>
                <h2>Weekly Discussion Group</h2>
                <span class="status active">Every Tuesday @ 18:00</span>
            </div>
            <div class="activity-content">
                <div class="activity-description">
                    <p>Our Weekly Discussion Group provides a casual forum for discussing recent papers, concepts, and developments in AI safety. These sessions are open to anyone interested in the field, regardless of prior knowledge.</p>
                    <p>Each week features a different topic, announced in advance through our mailing list and Telegram group.</p>

                    <h3>Format</h3>
                    <ul>
                        <li>90-minute discussions led by a rotating facilitator</li>
                        <li>Short presentation of the week's topic (15-20 minutes)</li>
                        <li>Open discussion and Q&A</li>
                        <li>Optional pre-reading materials shared in advance</li>
                    </ul>

                    <h3>Participation</h3>
                    <p>No registration is required. Simply show up! If you're attending for the first time, we recommend arriving 10 minutes early to meet the organizers.</p>
                </div>
                <div class="activity-sidebar">
                    <div class="activity-details-card">
                        <h3>Next Discussion</h3>
                        <ul class="details-list">
                            <li><strong>Date:</strong> March 25, 2025</li>
                            <li><strong>Time:</strong> 18:00 - 19:30</li>
                            <li><strong>Location:</strong> Pabellon 0+inf, Room 1603, Ciudad Universitaria</li>
                            <li><strong>Topic:</strong> Interpretability Methods</li>
                            <li><strong>Facilitator:</strong> Eitan Sprejer</li>
                        </ul>
                        <a href="https://t.me/+zfvMHU8TaAhjNjVh" class="btn btn-primary">Join Telegram for Updates</a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="paper-reading" class="activity-detail alt-bg">
        <div class="container">
            <div class="activity-header">
                <div class="activity-icon">üìù</div>
                <h2>Paper Reading Club</h2>
                <span class="status active">Every Friday @ 17:00</span>
            </div>
            <div class="activity-content">
                <div class="activity-description">
                    <p>The Paper Reading Club conducts deep dives into foundational and recent papers in AI safety research. Unlike the more casual discussion group, this activity involves a thorough examination of specific research papers.</p>
                    <p>Participants are expected to read the selected paper in advance and come prepared to discuss its methods, results, and implications.</p>

                    <h3>Paper Selection Criteria</h3>
                    <ul>
                        <li>Importance to the field of AI safety</li>
                        <li>Technical relevance to current research directions</li>
                        <li>Mix of foundational papers and recent publications</li>
                        <li>Accessibility to graduate and advanced undergraduate students</li>
                    </ul>

                    <h3>Session Format</h3>
                    <ul>
                        <li>Brief overview of the paper (5-10 minutes)</li>
                        <li>Section-by-section discussion</li>
                        <li>Examination of methods and results</li>
                        <li>Critical evaluation of claims and limitations</li>
                        <li>Discussion of potential follow-up research</li>
                    </ul>

                </div>
                <div class="activity-sidebar">
                    <div class="activity-details-card">
                        <h3>Next Paper Session</h3>
                        <ul class="details-list">
                            <li><strong>Date:</strong> March 21, 2025</li>
                            <li><strong>Time:</strong> 17:00 - 18:30</li>
                            <li><strong>Location:</strong> Pabellon 0+inf, Room 1603, Ciudad Universitaria</li>
                            <li><strong>Paper:</strong> "Mechanistic Interpretability for Language Models"</li>
                            <li><strong>Discussion Lead:</strong> Eitan Sprejer</li>
                        </ul>
                        <a href="resources.html#papers" class="btn btn-primary">Access Reading List</a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="mech-interp" class="activity-detail">
        <div class="container">
            <div class="activity-header">
                <div class="activity-icon">üß†</div>
                <h2>Mech Interp Course</h2>
                <span class="status upcoming">Starts June 2025</span>
            </div>
            <div class="activity-content">
                <div class="activity-description">
                    <p>The Mechanistic Interpretability Course is an intensive 1-month program focused on techniques for understanding the internal mechanisms of neural networks. This course combines theoretical learning with hands-on projects.</p>
                    <p>Mechanistic interpretability is a key area of AI safety research, aiming to make AI systems more transparent and understandable.</p>

                    <h3>Curriculum Overview</h3>
                    <ul>
                        <li>Foundations of neural network architectures</li>
                        <li>Feature visualization techniques</li>
                        <li>Circuit analysis in transformer models</li>
                        <li>Techniques for analyzing attention mechanisms</li>
                        <li>Gradient-based attribution methods</li>
                        <li>Final project: Interpreting a specific model component</li>
                    </ul>

                    <h3>Time Commitment</h3>
                    <ul>
                        <li>2 lectures per week (2 hours each)</li>
                        <li>1 practical session per week (3 hours)</li>
                        <li>Individual project work (5-10 hours per week)</li>
                        <li>Final project presentation</li>
                    </ul>

                    <h3>Prerequisites</h3>
                    <ul>
                        <li>Strong programming skills (Python)</li>
                        <li>Experience with deep learning frameworks (PyTorch preferred)</li>
                        <li>Familiarity with basic neural network architectures</li>
                        <li>Linear algebra and calculus</li>
                    </ul>
                </div>
                <div class="activity-sidebar">
                    <div class="activity-details-card">
                        <h3>Course Details</h3>
                        <ul class="details-list">
                            <li><strong>Duration:</strong> 4 weeks</li>
                            <li><strong>Start Date:</strong> June 2, 2025</li>
                            <li><strong>End Date:</strong> June 27, 2025</li>
                            <li><strong>Application Deadline:</strong> May 15, 2025</li>
                            <li><strong>Location:</strong> Hybrid (In-person & Zoom)</li>
                            <li><strong>Instructors:</strong> Dr. Laura Fernandez, Carlos Mendez</li>
                        </ul>
                        <a href="contact.html#mech-interp" class="btn btn-primary">Express Interest</a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="calendar">
        <div class="container">
            <h2>Upcoming Events Calendar</h2>
            <div class="calendar-embed">
                <iframe src="https://calendar.google.com/calendar/embed?src=aisafetyarg%40gmail.com&ctz=America%2FArgentina%2FBuenos_Aires" style="border: 0" width="800" height="600" frameborder="0" scrolling="no"></iframe>
            </div>
            <div class="calendar-actions">
                <a href="https://calendar.google.com/calendar/u/2?cid=YWlzYWZldHlhcmdAZ21haWwuY29t" class="btn btn-secondary" target="_blank" rel="noopener noreferrer">Subscribe to Google Calendar of All Events</a>
            </div>
        </div>
    </section>


    <footer class="site-footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-logo">
                    <div class="logo">BAISH - Buenos Aires AI Safety Hub</div>
                    <p class="tagline">Ensuring beneficial AI through research and education.</p>
                </div>
                <div class="footer-links">
                    <div class="link-group">
                        <h4>Pages</h4>
                        <ul>
                            <li><a href="index.html">Home</a></li>
                            <li><a href="about.html">About</a></li>
                            <li><a href="activities.html">Activities</a></li>
                            <li><a href="resources.html">Resources</a></li>
                            <li><a href="contact.html">Contact</a></li>
                        </ul>
                    </div>
                    <div class="link-group">
                        <h4>Connect</h4>
                        <ul>
                            <li><a href="mailto:aisafetyarg@gmail.com">Email</a></li>
                            <li><a href="https://t.me/+zfvMHU8TaAhjNjVh">Telegram</a></li>
                            <li><a href="https://www.instagram.com/aisafetyarg">Instagram</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 BAISH - Buenos Aires AI Safety Hub. A student initiative at the University of Buenos Aires.</p>
            </div>
        </div>
    </footer>
</body>
</html>
